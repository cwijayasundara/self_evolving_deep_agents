# ---- API Keys (set the ones needed for your chosen provider) ----
# OpenAI (required for MODEL_PROVIDER=openai)
OPENAI_API_KEY=sk-...
# Ollama cloud (required when OLLAMA_API_KEY is set or :cloud suffix used)
# Get key from ollama.com → Settings → API Keys
# OLLAMA_API_KEY=...
# Tavily search (required for web research tool)
TAVILY_API_KEY=tvly-...
# Either LANGSMITH_API_KEY or LANGCHAIN_API_KEY works (for tracing)
LANGSMITH_API_KEY=lsv2_...

# ---- LangSmith tracing (auto-enabled when set) ----
LANGCHAIN_TRACING_V2=true
LANGSMITH_PROJECT=self-evolving-agent

# ---- Model configuration ----
# Uses init_chat_model() — supports 20+ providers.
# Set MODEL and MODEL_PROVIDER, or use "provider:model" prefix in MODEL.
#
# OpenAI (default):
MODEL=gpt-4o
MODEL_PROVIDER=openai
#
# Ollama cloud (use actual model tag from ollama.com/v1/models):
#   pip install "self-evolving-deep-agents[ollama]"
#   MODEL=qwen3.5:397b
#   MODEL_PROVIDER=ollama
#   OLLAMA_API_KEY=...
#
# Ollama local:
#   MODEL=qwen3.5
#   MODEL_PROVIDER=ollama
#   MODEL_BASE_URL=http://localhost:11434
#
# Anthropic:
#   pip install "self-evolving-deep-agents[anthropic]"
#   ANTHROPIC_API_KEY=sk-ant-...
#   MODEL=claude-sonnet-4-5-20250929
#   MODEL_PROVIDER=anthropic
#
# Groq:
#   pip install "self-evolving-deep-agents[groq]"
#   GROQ_API_KEY=gsk_...
#   MODEL=llama-3.3-70b-versatile
#   MODEL_PROVIDER=groq
#
# Provider prefix (no MODEL_PROVIDER needed):
#   MODEL=ollama:qwen3.5:397b

# Optional: custom base URL for Ollama or OpenAI-compatible endpoints
# MODEL_BASE_URL=http://localhost:11434

# ---- Evolution settings ----
MAX_EVOLUTION_CYCLES=5
BATCH_SIZE=3

# ---- Directory paths (relative to project root) ----
SKILLS_DIR=skills
PROMPTS_DIR=prompts
MEMORY_DIR=memory
